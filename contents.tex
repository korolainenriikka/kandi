\chapter{Introduction}

%1st paragraph/section: context summary: why
\section{context summary, why, and motivation}
summary on maritime context

list of high level components: data ingestion, model development & iterating & trainig environment, model library, model inference. we are focusing on inference

motivation: intention is to find inference system strengths/weaknesses that can be applied to other extreme scale sensor data systems as well

another point of motivation: in the literature on architectures for iot or ml+iot or preserving knowledge in ML: there is little input on why certain decisions were made. this explains the why's

%2nd paragraph/section: question, results, methodology
\section{research questions, results summary and methodology}

primary question: Which training and inference setup would be optimal for enabling lifelong learning / incremental learning / retraining in the specific context of vesselai?

dealing with concept drift

secondary questions:

where (location (edge, fog, cloud) & type of hardware (not exact but like supercomputer, regular computer or mini device like raspberry pi/arduino)) should the models be deployed on?

things to exclude: details on stream processing, inference system details

aspects to consider: version management in central vs edge inference, lifelong learning management, concept drift in iot: how to avoid (concept drift still fully unresearched!)

how big is the messaging overhead in a highly distributed system

do the specialities of this context, the low end to end latency requirement, very high geographical and no private data (no private from d10.1) impact something we consider so much that an ''unconventional'' design decision is justified? (privacy matters affect design a lot \cite{iotsystems})

a point of motivation from D1.1 moving beyond the state of the art section: ''the time is ripe  to  rethink  whether  cloud  computing  is  the  only  architecture  able  to  support  IoT  applications, especially  in  the  case  of  smart applications,  where  static  and  mobile  IoT  devices  will  be  widely embedded  in  infrastructures.  It  is  worth  investigating  an  overall  orchestration  of  the  computational resources  available  today  that  can  take  advantage  of  the  edge-fog-cloud  continuum'' addition: to make lifelong learning possible


results summary

\section{Chapter roles}

% this should maybe be shortened? in many papers this section is much shorter and only outlines the highest level, ie here chapters maybe

The rest of this thesis is organized as follows:

Chapter 2 presents the necessary background knowledge to the reader. First, a general introduction into distributed sensor systems with machine learning will be given. The most important design decisions; edge-fog-or-cloud deployments and incoming data processing scheme as batch, micro-batch or stream, will be quickly presented.

A more thorough state-of-the-art inspection is given in the domain of machine learning on the methods for extending the lifetime of a model. The main challenges in this, the concept drift and the stability-plasticity-dilemma are defined, and then the existing solutions for addressing the challenges are presented.

Then follows a quick interlude into high performance computing, where the power and application requirements of the newest HPC systems are given.

Lastly, the general context for the VesselAI project will be described. The specialities of the maritime domain and the nature of the data sources will be dissected, after which the project pilots and general goals will be presented. From these the general requirements will be listed and the main challenge of the project is identified: how to organize a workflow for efficient re-training of the models.

Chapter 3 analyzes and compares the various systems approaches presented previously from the point of view of the case studied. The main abstract components of the system, stream processing, training workflow, and deployment scheme are each inspected for the optimal trade-offs. After this, the VesselAI system proposal is presented, alongside reasoning why these decision should be made. It is also considered whether there is enough evidence to make the presented conclusions, or if there are several good-seeming options to choose from.

The paper is concluded with discussion on if the conclusions reached with the case study are applicable to other systems with similar requirements. Especially applicability to other cases with highly voluminous data combined with a long model lifetime is emphasized.

\section{acm classification,  keyword ideas}

acm:
Information systems → Information systems applications →
Spatial-temporal systems → Data streaming (from \cite{uprctrajectorysystem})

end to end + sensor data (iot) + machine learning + maritime + inference + lifelong learning

Distributed Machine Learning, Internet of Things, Training, Serving (from \cite{mliot})

title wordplay:

Sensor data systems at extreme scale / for scale

Enabling knowledge retention in a sensor-based machine learning big data system: a case study

\chapter{Context and Background}

\section{Knowledge retention techniques for machine learning}

anything used later that my level reader might not understand comes here

define federated learning and lifelong learning, online learning?

\section{On Big Data Systems}

% maybe edit the heading to also include sensor/IoT

to add here: a high-enough abstraction / "charting of the field" of big data systems in general

the high level components, d1.2 p 32 has one good starting point

definition of a user request in this context: the human is not considered, they use the ui. user is the application making requests to the system. these might be preprocessing-related or actual human user requests

%\subsection{the Lambda and Kappa architectures}
% this is probably off topic.
% this is the content on lambda & kappa that is probably needed content-wise. only needs better writing.

\subsection{Data ingestion: reference architectures for stream processing}

the initial motivation behind lambda: to beat cap theorem's inherent need to tradeoff between consistency and availability \cite{lambdakappa}

nathan marz presenting a system that supposedly beats cap. how: treat data as immutable, emphasize importance of preparing for human error, and splitting a database into two systems, batch and speed layer. The batch layer does order of hours long preprocessing of queries, speed layer has  abstracted within itself a complex system for handling the data from the latest hours to make also that available for querying. Fault tolerance comes mainly from the fact that the speed layer is possible to empty to the batch queue and restart in case of failure or overload.

the most known criticism to lambda, a blog post by Jay Kreps \cite{questioninglambda}, acknowledged its strengths in seeing data as immutable and highlighting the possibility that data may be needed to reprocess due to changes in application code. The main points of criticism were the argument that lambda does not actually beat cap but still compromises some consistency, that deeming real-time stream processing as inherently faulty and approximate "does not make sense" and is only a fault in the current tools \cite{questioninglambda}. The post along with other sources deem the most important flaw in lambda to be the fact that maintaining and syncronizing separate code bases for batch and stream layer to be redundantly complex \cite{uber} \cite{facebook}. At the same time multiple system analyses name maintainability the most or one of the most important trait about a big data system \cite{facebook} \cite{storm@twitter}.

As an alternative approach to solve these problems, Kreps proposed a different architecture called the Kappa architecture. It is otherwise similar to lambda but only has either batch or speed layer, usually speed layer in a for of highly parallelized stream processor. This mitigates the duplication problem while keeping other strengths from lambda, but the ability of giving fast answers to queries is lost.

(\cite{D1.1} states that both lambda and kappa mitigate human errors ''by  updating  the  code  and  running  it  again  on  the historical  data '')

% problems with both lambda&kappa, structure needs reorder because this does not make sense before vesselai requirement specs

fundamental assumptions of both systems:  the need almost instant execution times is assumed \cite{lambdakappa}. This is not required in vesselai. also, not stated in the sources on lambda and kappa but still assumed: that we are able to tell before the user query what exactly is going to be queried. If in vesselai the model may change and with that the query as well, or more importantly the queries regard only a mini fraction of geographical space so preprocessing the full globe and needing a percent of the preprocessed has a potential of being a grande waste of computation in the maritime case (my judgement). for the latter point it is possible that neither lambda or kappa are good.

- all the apache systems: what they are what is each used for, a very short description

\subsection{On machine learning IoT systems: the inference paradigms}

here:

edge vs fog vs cloud

OCF is The Open Connectivity Foundation. add below + the proper source

The definition of fog computing is the following, as stated by the the OCF (in \cite{fogsurvey} reference [42]): “Fog computing is a horizontal, system-level architecture that distributes computing, storage, control and networking functions closer to the users along a cloud-to-thing continuum.” (but not only entirely to the edge). Or, put differently by \cite{fogsurvey} for a clearer mental image: "The Fog is a Cloud closer to the ground."


%\section{the evaluation dimensions}

this sect should be removed and added as a part of the introduction.

For this thesis, dimensions are defined as traits by which various systems can be evaluated. These are:

latency: the time it takes from user input until they get their desired output,

scalability: at which data volume per time unit the system faces bottlenecks,

accuracy: how true the predictions made by the system are and how much information the system is able to give its user about the predictions' accuracy.

throughput: how many user requests the system is able to handle (this trait may not be necessary)

a word for how easy something is to improve on...: multiple mature big data systems descriptions mentioned this as the most of one of the most important trait in the system \cite{uber} \cite{facebook}.

\section{High-performance Computing}

something on how fast is fast, how powerful the hpc systems are compared to laptops

what are raspberry pi and arduino and how their power compares to a standard laptop

\section{The case: context and requirements for machine learning in the maritime domain}

Maritime as a domain of application for a sensor-based machine learning system is in a few ways significantly different from many others. The most obvious difference is its global nature; domains like smart cities also have to take into account the fact that there is some geographical distribution, but with the seas covering x\% of the earths' surface, the extent of geographical distribution in the maritime context is on a whole new level.

With the vastness of the seas and its vital nature for world trade, the amount of vessel traffic is large even in comparison to other big data applications. Due to international regulation vessels have to send update signals on their status from every few minutes to every 2 seconds, depending on their speed and course \cite{maritimeinformatics}. With approximately 100, 000 ships sailing the world oceans daily (a source from \cite{maritimeinformatics} states this), this leads to several billion messages sent each day. To this exceptional amount of data we refer to as \textit{extreme-scale data} in this work. In addition to this, in order to provide valid maritime intelligence, other types of data such as geographical information and weather updates, are needed. Therefore, the data is not only highly voluminous, but also heterogeneous, coming in both static and dynamic forms at different velocities.

Added to scale, another specific of this context is speed. Depending on the size of the vessel, it takes from minutes to up to an hour to change the course of the vessel. This means that for the AI services targeted for navigational purposes the end-to-end latencies need not to be faster than the order of minutes, and execution times of up to 30-60 minutes can be acceptable. For other AI services end-to-end times in order of seconds may be aimed for, but achieving sub-second latencies as is often the goal in literature (citations...), is unnecessary, even detrimental to the success of the system operation: for speed other more important traits would have to be deprioritised, which in this case would do more harm than good.

The main data source, the status signal data sent by vessels, called \textit{automatic identification system} (AIS) data, also has its specialities. AIS is a form of sensor data and has two types: static messages containing information such as name, destination and ship characteristics, and dynamic messages with information on the vessels' location, speed, heading, and rate of turn. The challenge with AIS data is both its highly fluctuating reporting intervals and especially its unreliability.  Things such as manually written destinations, faulty timestamping, lack of universal identifiers, misreported locations, and even illegal traffic camouflaging their operations, make identifying and correcting erroneous data both difficult and computationally intensive.

The goal on the application level of the VesselAI project is to provide the following four pilot services to users: vessel route forecasting for traffic monitoring and management, design of optimal ship energy systems, operating autonomous ships in short sea transport, and weather-optimized routing for long-distance voyages. More abstract goals are to find a system that is suitable for both managing extreme-scale data and facilitating long model lifetimes. The goal is also to be able to fully utilize the most modern high performance computing infrastructures in an optimal way.

With this context specification in mind, the following guidelines on the system aimed for can be stated: the high volume and relatively low quality of the data sets high demands on the training part of the pipeline, whereas the inference side has less strict requirements. The fact that the pilot cases are clearly defined and at least as of date there are no plans for additional applications, the primary challenge is maintaining and updating the models for these specific problem, not being ready to cope with the possibility of new problems being added, as is sometimes the case in other systems (find citations here...).  Summarized: the primary challenge for this system is to find a way of organising the training workflow to maintain accuracy throughout the model lifespan. This is the primary topic of inspection in the following chapters.

% TO ADD HERE: the data processed is not personal in any way and the case studied is in this sense very different from many others. dunno id d10 should be cited because it was marked confidential

% TO ADD (MAYBE): this is sensor stuff so it is kind of IoT like but it is different in many respects to what is usually thought of when talking about IoT like smart ovens and all those

% TO ADD: the data used is spatiotemporal. Kind of mentioned kind of not mentioned. Could be emphasized more if needed in an argument

%outline:

%maritime
%	global
%	geo distributed
%	volume is huge (ais message rates & amount of traffic: give numbers)
%	time scales: it takes minutes to an hour to turn a cargo vessel

%ais
%	what is AIS
%	a lot of features that are unreliable
%	identifying the erroneus might be very difficult: smugglers' disguising ais example
%	... check maritime informatics for more

%the project
%	the pilots I-V: what each one aims for
%		these ml problems are difficult
%	abstract aims
%		deal with extreme scale data
%		facilitate continuous learning
%		utilize modern HPC
%	... check deliverables for exact aims
%
%the system
%	we combine different data sets
%		static and dynamic, fast and slow paced
%			examples: map data, weather data, sensor data
%	many models only need a small fraction of the data
%

%combine these: the requirements
%we need to know what we need and what we do not need for sure to know which system design makes sense.

%we need throughput, not individual request answer speed (millisecond speed unnecessary)
%pilots defined: we need to keep models up to date, not be ready to expand to new models as much
%the machine learning paradigm and workflow of choice needs to be mature enough for industry implementation
%	in a complex scenario.
%inference time windows are big. the challenge is facilitating training.

%then: present abstract illustration of the architecture and state: THIS is %the spot which we investigate.


\chapter{vesselai-like systems}

\section{inference paradigm}

discuss here: edge v couldlet v fog v cloud

+ and - for fog, from \cite{fogsurvey}

+'s that matter: saves bandwidth, mitigates problems with hostile areas that have fragile net connections (fog is stated to be fundamental in solving this problem), has reached a good enough maturity

+'s that do not matter: saves time (in range 66-302 ms), is somewhat more private, context awareness: able to adjust to location is probably not something the models are able to benefit from because edge training is most likely not computationally feasible

-'s: adds compexity by distribution and heterogenity: " imposes non-trivial orchestration issues", cloud is more energy efficient (fot this check [120] from \cite{fogsurvey}),

so: fog has drawbacks in complexity that are not acceptable considering that the advantages gotten with it are largely irrelevant.

\section{facilitating knowledge retention}

a tradeoff: federated vs centralized learning \cite{iotsurvey}

edge vs central inference: if on edge the model needs to be small \cite{iotsurvey}

\section{stream processing}

\section{other possible discussions to add}

\begin{itemize}
    \item where to do data cleaning
\end{itemize}

\chapter{the vesselai system}

i e the results i get
